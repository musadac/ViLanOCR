{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install git+https://github.com/huggingface/transformers\n",
    "!pip install sentencepiece\n",
    "!pip3 install jiwer jiwer\n",
    "!pip3 install python-socketio\n",
    "!pip3 install \"python-socketio[client]\"\n",
    "!pip3 install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T19:40:38.038023Z",
     "iopub.status.busy": "2023-03-02T19:40:38.037264Z",
     "iopub.status.idle": "2023-03-02T19:40:38.048625Z",
     "shell.execute_reply": "2023-03-02T19:40:38.047247Z",
     "shell.execute_reply.started": "2023-03-02T19:40:38.037978Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T19:40:38.050723Z",
     "iopub.status.busy": "2023-03-02T19:40:38.050173Z",
     "iopub.status.idle": "2023-03-02T19:40:39.167772Z",
     "shell.execute_reply": "2023-03-02T19:40:39.166539Z",
     "shell.execute_reply.started": "2023-03-02T19:40:38.050686Z"
    }
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T19:43:19.645467Z",
     "iopub.status.busy": "2023-03-02T19:43:19.644847Z",
     "iopub.status.idle": "2023-03-02T19:43:19.651343Z",
     "shell.execute_reply": "2023-03-02T19:43:19.649935Z",
     "shell.execute_reply.started": "2023-03-02T19:43:19.645421Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = r\"\"\n",
    "data_csv = \"spemain.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T19:43:20.625523Z",
     "iopub.status.busy": "2023-03-02T19:43:20.624781Z",
     "iopub.status.idle": "2023-03-02T19:43:20.676701Z",
     "shell.execute_reply": "2023-03-02T19:43:20.675649Z",
     "shell.execute_reply.started": "2023-03-02T19:43:20.625483Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_csv, names=['id','text']).iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T19:43:21.285959Z",
     "iopub.status.busy": "2023-03-02T19:43:21.285300Z",
     "iopub.status.idle": "2023-03-02T19:43:21.659220Z",
     "shell.execute_reply": "2023-03-02T19:43:21.658118Z",
     "shell.execute_reply.started": "2023-03-02T19:43:21.285917Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[df['text'].str.split().str.len().gt(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['text'].str.split().str.len().lt(250)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T19:43:21.661672Z",
     "iopub.status.busy": "2023-03-02T19:43:21.660955Z",
     "iopub.status.idle": "2023-03-02T19:43:21.679086Z",
     "shell.execute_reply": "2023-03-02T19:43:21.677951Z",
     "shell.execute_reply.started": "2023-03-02T19:43:21.661632Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T19:43:22.418783Z",
     "iopub.status.busy": "2023-03-02T19:43:22.418397Z",
     "iopub.status.idle": "2023-03-02T19:43:22.452995Z",
     "shell.execute_reply": "2023-03-02T19:43:22.451843Z",
     "shell.execute_reply.started": "2023-03-02T19:43:22.418749Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train,df_test = train_test_split(df,test_size = 0.1,random_state=0)\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "sum([len(str(x).split()) for x in df_train['text']])/len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max([len(str(x).split()) for x in df_train['text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T19:43:22.878442Z",
     "iopub.status.busy": "2023-03-02T19:43:22.877478Z",
     "iopub.status.idle": "2023-03-02T19:43:22.889757Z",
     "shell.execute_reply": "2023-03-02T19:43:22.888584Z",
     "shell.execute_reply.started": "2023-03-02T19:43:22.878384Z"
    }
   },
   "outputs": [],
   "source": [
    "sum([len(str(x).split()) for x in df_test['text']])/len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T19:43:23.152797Z",
     "iopub.status.busy": "2023-03-02T19:43:23.152132Z",
     "iopub.status.idle": "2023-03-02T19:43:23.165348Z",
     "shell.execute_reply": "2023-03-02T19:43:23.164027Z",
     "shell.execute_reply.started": "2023-03-02T19:43:23.152763Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from PIL import Image, ImageOps, ImageFilter, ImageEnhance, ImageDraw\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "def Blur(img):\n",
    "    return img.filter(ImageFilter.BLUR)\n",
    " \n",
    "def GaussianBlur(img):\n",
    "    return img.filter(ImageFilter.GaussianBlur(radius = random.randint(1, 10)))\n",
    "\n",
    "def BoxBlur(img):\n",
    "    return img.filter(ImageFilter.BoxBlur(radius = random.randint(1, 10)))\n",
    "\n",
    "def Contrast(img):\n",
    "    enhancer = ImageEnhance.Contrast(img)\n",
    "    return enhancer.enhance(random.randint(0, 6))\n",
    "\n",
    "def pixelate(img):\n",
    "    imgSmall = img.resize((256, 256))\n",
    "    return imgSmall.resize(img.size,Image.NEAREST)\n",
    "\n",
    "def rotate(img):\n",
    "    return img.rotate(random.randint(1, 45))\n",
    "\n",
    "def prespective(img):\n",
    "    width, height = img.size\n",
    "    m = -0.5\n",
    "    xshift = abs(m) * width\n",
    "    new_width = width + int(round(xshift))\n",
    "    return img.transform((new_width, height), Image.AFFINE,\n",
    "            (1, m, -xshift if m > 0 else 0, 0, 1, 0), Image.BICUBIC)\n",
    "\n",
    "def translate(img):\n",
    "    a = 1\n",
    "    b = 0\n",
    "    c = 0 \n",
    "    d = 0\n",
    "    e = 1\n",
    "    f = 0 \n",
    "    return img.transform(img.size, Image.AFFINE, (a, b, c, d, e, f))\n",
    "\n",
    "\n",
    "def noisy(noise_typ,image):\n",
    "    if noise_typ == \"gauss\":\n",
    "        row,col = image.size\n",
    "        ch = 3\n",
    "        mean = 0\n",
    "        var = 0.1\n",
    "        sigma = var**0.5\n",
    "        gauss = np.random.normal(mean,sigma,(row,col,ch))\n",
    "        gauss = gauss.reshape(col,row,ch)\n",
    "        noisy = image + gauss\n",
    "        return Image.fromarray(noisy)\n",
    "    elif noise_typ == \"s&p\":\n",
    "        row,col = image.size\n",
    "        ch = 3\n",
    "        s_vs_p = 0.5\n",
    "        amount = 0.004\n",
    "        out = np.copy(image)\n",
    "        # Salt mode\n",
    "        num_salt = np.ceil(amount * image.size * s_vs_p)\n",
    "        coords = [np.random.randint(0, i - 1, int(num_salt))\n",
    "                for i in image.size]\n",
    "        out[coords] = 1\n",
    "\n",
    "        # Pepper mode\n",
    "        num_pepper = np.ceil(amount* image.size * (1. - s_vs_p))\n",
    "        coords = [np.random.randint(0, i - 1, int(num_pepper))\n",
    "                for i in image.size]\n",
    "        out[coords] = 0\n",
    "        return out\n",
    "    elif noise_typ == \"poisson\":\n",
    "        vals = len(np.unique(image))\n",
    "        vals = 2 ** np.ceil(np.log2(vals))\n",
    "        noisy = np.random.poisson(image * vals) / float(vals)\n",
    "        return noisy\n",
    "    elif noise_typ ==\"speckle\":\n",
    "        row,col = image.size\n",
    "        ch = 3\n",
    "        gauss = np.random.randn(row,col,ch)\n",
    "        gauss = gauss.reshape(row,col,ch)        \n",
    "        noisy = image + image * gauss\n",
    "        return noisy\n",
    "\n",
    "def Vgrid(img):\n",
    "    W, H = img.size\n",
    "    max_width=3\n",
    "    mag=-1\n",
    "    if mag<0 or mag>max_width:\n",
    "            line_width = np.random.randint(1, max_width)\n",
    "            image_stripe = np.random.randint(1, max_width)\n",
    "    else:\n",
    "        line_width = 1\n",
    "        image_stripe = 3 - mag\n",
    "\n",
    "    n_lines = H // (line_width + image_stripe) + 1\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for i in range(1, n_lines):\n",
    "        y = image_stripe*i + line_width*(i-1)\n",
    "        draw.line([(0,y), (W, y)], width=line_width, fill='black')\n",
    "    return img\n",
    "\n",
    "def Hgrid(img):\n",
    "    W, H = img.size\n",
    "    max_width=3\n",
    "    mag=-1\n",
    "    if mag<0 or mag>max_width:\n",
    "        line_width = np.random.randint(1, max_width)\n",
    "        image_stripe = np.random.randint(1, max_width)\n",
    "    else:\n",
    "        line_width = 1\n",
    "        image_stripe = 3 - mag\n",
    "\n",
    "    n_lines = W // (line_width + image_stripe) + 1\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for i in range(1, n_lines):\n",
    "        x = image_stripe*i + line_width*(i-1)\n",
    "        draw.line([(x,0), (x,H)], width=line_width, fill='black')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T19:43:23.975325Z",
     "iopub.status.busy": "2023-03-02T19:43:23.974607Z",
     "iopub.status.idle": "2023-03-02T19:43:23.986312Z",
     "shell.execute_reply": "2023-03-02T19:43:23.984667Z",
     "shell.execute_reply.started": "2023-03-02T19:43:23.975288Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class MedicalDataset(Dataset):\n",
    "    def __init__(self, root_dir, df, processor, max_target_length=128):\n",
    "        self.root_dir = root_dir\n",
    "        self.df = df\n",
    "        self.processor = processor\n",
    "        self.max_target_length = max_target_length\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get file name + text \n",
    "        file_name = self.df['id'][idx].strip()\n",
    "        text = str(self.df['text'][idx])\n",
    "        # prepare image (i.e. resize + normalize)\n",
    "        if os.path.exists(self.root_dir+file_name):\n",
    "            image = Image.open(self.root_dir+file_name).convert(\"RGB\")\n",
    "        else:\n",
    "            print(self.df['id'][idx])\n",
    "            file_name = self.df['id'][0]\n",
    "            text = str(self.df['text'][0])\n",
    "            image = Image.open(self.root_dir+file_name).convert(\"RGB\")\n",
    "        doaug = random.randint(2, 100)\n",
    "        if doaug == 2:\n",
    "            image = Blur(image)\n",
    "        elif doaug == 3:\n",
    "            image = GaussianBlur(image)\n",
    "        elif doaug == 4:\n",
    "            image = BoxBlur(image)\n",
    "        elif doaug == 5:\n",
    "            image = pixelate(image)\n",
    "        elif doaug == 6:\n",
    "            image =  rotate(image)\n",
    "        elif doaug == 7:\n",
    "             image = prespective(image)\n",
    "        elif doaug == 8:\n",
    "            image =  Vgrid(image)\n",
    "        elif doaug == 9:\n",
    "            image =  Hgrid(image)\n",
    "        try:\n",
    "            pixel_values = self.processor(image, return_tensors=\"pt\").pixel_values\n",
    "        except:\n",
    "            file_name = self.df['id'][0]\n",
    "            text = str(self.df['text'][0])\n",
    "            # prepare image (i.e. resize + normalize)\n",
    "            image = Image.open(self.root_dir+file_name).convert(\"RGB\")\n",
    "            pixel_values = self.processor(image, return_tensors=\"pt\").pixel_values\n",
    "        # add labels (input_ids) by encoding the text\n",
    "        labels = self.processor.tokenizer(text, \n",
    "                                          padding=\"max_length\", \n",
    "                                          max_length=self.max_target_length,truncation=True).input_ids\n",
    "        # important: make sure that PAD tokens are ignored by the loss function\n",
    "        labels = [label if label != self.processor.tokenizer.pad_token_id else -100 for label in labels]\n",
    "\n",
    "        encoding = {\"pixel_values\": pixel_values.squeeze(), \"labels\": torch.tensor(labels)}\n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T19:43:25.547679Z",
     "iopub.status.busy": "2023-03-02T19:43:25.546948Z",
     "iopub.status.idle": "2023-03-02T19:43:25.561329Z",
     "shell.execute_reply": "2023-03-02T19:43:25.560166Z",
     "shell.execute_reply.started": "2023-03-02T19:43:25.547640Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from contextlib import contextmanager\n",
    "from transformers import MBartTokenizer, ViTImageProcessor, XLMRobertaTokenizer\n",
    "from transformers import ProcessorMixin\n",
    "\n",
    "\n",
    "class CustomOCRProcessor(ProcessorMixin):\n",
    "    attributes = [\"image_processor\", \"tokenizer\"]\n",
    "    image_processor_class = \"AutoImageProcessor\"\n",
    "    tokenizer_class = \"AutoTokenizer\"\n",
    "\n",
    "    def __init__(self, image_processor=None, tokenizer=None, **kwargs):\n",
    "        if \"feature_extractor\" in kwargs:\n",
    "            warnings.warn(\n",
    "                \"The `feature_extractor` argument is deprecated and will be removed in v5, use `image_processor`\"\n",
    "                \" instead.\",\n",
    "                FutureWarning,\n",
    "            )\n",
    "            feature_extractor = kwargs.pop(\"feature_extractor\")\n",
    "\n",
    "        image_processor = image_processor if image_processor is not None else feature_extractor\n",
    "        if image_processor is None:\n",
    "            raise ValueError(\"You need to specify an `image_processor`.\")\n",
    "        if tokenizer is None:\n",
    "            raise ValueError(\"You need to specify a `tokenizer`.\")\n",
    "\n",
    "        super().__init__(image_processor, tokenizer)\n",
    "        self.current_processor = self.image_processor\n",
    "        self._in_target_context_manager = False\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        # For backward compatibility\n",
    "        if self._in_target_context_manager:\n",
    "            return self.current_processor(*args, **kwargs)\n",
    "\n",
    "        images = kwargs.pop(\"images\", None)\n",
    "        text = kwargs.pop(\"text\", None)\n",
    "        if len(args) > 0:\n",
    "            images = args[0]\n",
    "            args = args[1:]\n",
    "\n",
    "        if images is None and text is None:\n",
    "            raise ValueError(\"You need to specify either an `images` or `text` input to process.\")\n",
    "\n",
    "        if images is not None:\n",
    "            inputs = self.image_processor(images, *args, **kwargs)\n",
    "        if text is not None:\n",
    "            encodings = self.tokenizer(text, **kwargs)\n",
    "\n",
    "        if text is None:\n",
    "            return inputs\n",
    "        elif images is None:\n",
    "            return encodings\n",
    "        else:\n",
    "            inputs[\"labels\"] = encodings[\"input_ids\"]\n",
    "            return inputs\n",
    "\n",
    "    def batch_decode(self, *args, **kwargs):\n",
    "        return self.tokenizer.batch_decode(*args, **kwargs)\n",
    "\n",
    "    def decode(self, *args, **kwargs):\n",
    "        return self.tokenizer.decode(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T19:43:27.227443Z",
     "iopub.status.busy": "2023-03-02T19:43:27.227050Z",
     "iopub.status.idle": "2023-03-02T19:43:28.160380Z",
     "shell.execute_reply": "2023-03-02T19:43:28.159312Z",
     "shell.execute_reply.started": "2023-03-02T19:43:27.227409Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TrOCRProcessor\n",
    "\n",
    "image_processor = ViTImageProcessor.from_pretrained(\n",
    "    'microsoft/swin-base-patch4-window12-384-in22k'\n",
    ")\n",
    "tokenizer = MBartTokenizer.from_pretrained(\n",
    "    'facebook/mbart-large-50'\n",
    ")\n",
    "processor = CustomOCRProcessor(image_processor,tokenizer)\n",
    "train_dataset = MedicalDataset(root_dir=data_path,\n",
    "                           df=df_train,\n",
    "                           processor=processor,max_target_length=55)\n",
    "eval_dataset = MedicalDataset(root_dir=data_path,\n",
    "                           df=df_test,\n",
    "                           processor=processor,max_target_length=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T19:43:30.030485Z",
     "iopub.status.busy": "2023-03-02T19:43:30.029332Z",
     "iopub.status.idle": "2023-03-02T19:43:30.037382Z",
     "shell.execute_reply": "2023-03-02T19:43:30.036261Z",
     "shell.execute_reply.started": "2023-03-02T19:43:30.030432Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Number of training examples:\", len(train_dataset))\n",
    "print(\"Number of validation examples:\", len(eval_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T19:43:31.702429Z",
     "iopub.status.busy": "2023-03-02T19:43:31.701961Z",
     "iopub.status.idle": "2023-03-02T19:43:31.713525Z",
     "shell.execute_reply": "2023-03-02T19:43:31.712533Z",
     "shell.execute_reply.started": "2023-03-02T19:43:31.702375Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, pin_memory=True)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T19:41:28.865901Z",
     "iopub.status.busy": "2023-03-02T19:41:28.865595Z",
     "iopub.status.idle": "2023-03-02T19:41:29.524678Z",
     "shell.execute_reply": "2023-03-02T19:41:29.523215Z",
     "shell.execute_reply.started": "2023-03-02T19:41:28.865854Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import VisionEncoderDecoderModel\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T19:41:29.527491Z",
     "iopub.status.busy": "2023-03-02T19:41:29.526679Z",
     "iopub.status.idle": "2023-03-02T19:41:29.533258Z",
     "shell.execute_reply": "2023-03-02T19:41:29.532326Z",
     "shell.execute_reply.started": "2023-03-02T19:41:29.527442Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T19:41:29.537233Z",
     "iopub.status.busy": "2023-03-02T19:41:29.536448Z",
     "iopub.status.idle": "2023-03-02T19:42:39.185663Z",
     "shell.execute_reply": "2023-03-02T19:42:39.184617Z",
     "shell.execute_reply.started": "2023-03-02T19:41:29.537195Z"
    }
   },
   "outputs": [],
   "source": [
    "model = VisionEncoderDecoderModel.from_pretrained(\"musadac/vilanocr-single-urdu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T19:42:45.258316Z",
     "iopub.status.busy": "2023-03-02T19:42:45.257561Z",
     "iopub.status.idle": "2023-03-02T19:42:45.728144Z",
     "shell.execute_reply": "2023-03-02T19:42:45.726426Z",
     "shell.execute_reply.started": "2023-03-02T19:42:45.258278Z"
    }
   },
   "outputs": [],
   "source": [
    "model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
    "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "model.config.vocab_size = model.config.decoder.vocab_size\n",
    "model.config.eos_token_id = processor.tokenizer.sep_token_id\n",
    "model.config.max_length = 55 \n",
    "model.config.early_stopping = False\n",
    "model.config.no_repeat_ngram_size = 4\n",
    "model.config.length_penalty = 2.0\n",
    "model.config.num_beams = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T19:42:39.210668Z",
     "iopub.status.busy": "2023-03-02T19:42:39.210055Z",
     "iopub.status.idle": "2023-03-02T19:42:44.134353Z",
     "shell.execute_reply": "2023-03-02T19:42:44.133106Z",
     "shell.execute_reply.started": "2023-03-02T19:42:39.210629Z"
    }
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "print(\"model loaded to \",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T19:42:44.136471Z",
     "iopub.status.busy": "2023-03-02T19:42:44.136072Z",
     "iopub.status.idle": "2023-03-02T19:42:45.054727Z",
     "shell.execute_reply": "2023-03-02T19:42:45.053625Z",
     "shell.execute_reply.started": "2023-03-02T19:42:44.136431Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "cer_metric = load_metric(\"cer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T19:42:45.057440Z",
     "iopub.status.busy": "2023-03-02T19:42:45.056164Z",
     "iopub.status.idle": "2023-03-02T19:42:45.149108Z",
     "shell.execute_reply": "2023-03-02T19:42:45.148085Z",
     "shell.execute_reply.started": "2023-03-02T19:42:45.057398Z"
    }
   },
   "outputs": [],
   "source": [
    "import socketio\n",
    "import asyncio\n",
    "sio = socketio.Client()\n",
    "array_data_epochs = []\n",
    "def info_emit(name, epochs = 0, training_loss=0, valid_loss=0, total_epochs=0, ):\n",
    "    data = {\n",
    "        'id': sio.sid,\n",
    "        'name':name,\n",
    "        'epochs':epochs,\n",
    "        'training_loss':training_loss,\n",
    "        'valid_loss':valid_loss,\n",
    "        'total_epochs':total_epochs\n",
    "    }\n",
    "    try:\n",
    "        sio.connect('http://3.133.24.230:3033')\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        sio.emit('send_message', data)\n",
    "        array_data_epochs.append(data)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T19:42:45.152227Z",
     "iopub.status.busy": "2023-03-02T19:42:45.151887Z",
     "iopub.status.idle": "2023-03-02T19:42:45.157895Z",
     "shell.execute_reply": "2023-03-02T19:42:45.156824Z",
     "shell.execute_reply.started": "2023-03-02T19:42:45.152199Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_cer(pred_ids, label_ids):\n",
    "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return cer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T19:42:45.160035Z",
     "iopub.status.busy": "2023-03-02T19:42:45.159389Z",
     "iopub.status.idle": "2023-03-02T19:42:45.171400Z",
     "shell.execute_reply": "2023-03-02T19:42:45.170388Z",
     "shell.execute_reply.started": "2023-03-02T19:42:45.159997Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    label_str = processor.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"cer\": cer}\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T19:42:45.174384Z",
     "iopub.status.busy": "2023-03-02T19:42:45.173761Z",
     "iopub.status.idle": "2023-03-02T19:42:45.187839Z",
     "shell.execute_reply": "2023-03-02T19:42:45.186923Z",
     "shell.execute_reply.started": "2023-03-02T19:42:45.174347Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T19:42:45.190159Z",
     "iopub.status.busy": "2023-03-02T19:42:45.189658Z",
     "iopub.status.idle": "2023-03-02T19:42:45.214795Z",
     "shell.execute_reply": "2023-03-02T19:42:45.213542Z",
     "shell.execute_reply.started": "2023-03-02T19:42:45.190108Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=5e-5,\\\n",
    "                                                steps_per_epoch=len(train_dataloader), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T19:42:55.765468Z",
     "iopub.status.busy": "2023-03-02T19:42:55.764719Z",
     "iopub.status.idle": "2023-03-02T19:42:55.770319Z",
     "shell.execute_reply": "2023-03-02T19:42:55.769086Z",
     "shell.execute_reply.started": "2023-03-02T19:42:55.765428Z"
    }
   },
   "outputs": [],
   "source": [
    "name_of = \"Handwritten Urdu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-02T19:43:36.487003Z",
     "iopub.status.busy": "2023-03-02T19:43:36.486001Z",
     "iopub.status.idle": "2023-03-03T04:17:07.470890Z",
     "shell.execute_reply": "2023-03-03T04:17:07.468429Z",
     "shell.execute_reply.started": "2023-03-02T19:43:36.486936Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "save = \"./Urdufullmultiaug\"\n",
    "save_after_steps = 20000\n",
    "\n",
    "val_loss_m = 0\n",
    "val_loss_min = 999999\n",
    "stepsnow = 0\n",
    "for epoch in range(0,epochs):  # loop over the dataset multiple times\n",
    "   # train\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    counts = 0\n",
    "    train_cer = 0.0\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        # get the inputs\n",
    "        for k,v in batch.items():\n",
    "            batch[k] = v.cuda()            \n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "#         loss.backward()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "#         scheduler.step()\n",
    "        train_loss += loss.sum().item()\n",
    "        counts += 1\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "        cer = compute_cer(pred_ids=predictions, label_ids=batch[\"labels\"])\n",
    "        train_cer += cer \n",
    "#         info_emit(name_of,epoch,train_cer/counts,val_loss_m,epochs ) # train_cer\n",
    "        stepsnow+=1\n",
    "        if stepsnow  % save_after_steps == 0:\n",
    "            model.save_pretrained(\"./StepsSave/StepSys\"+str(save)+\"-\"+str(stepsnow)+'-'+str(train_cer/counts))\n",
    "    print(f\"Loss after epoch {epoch}:\", train_cer/len(train_dataloader))\n",
    "#     info_emit(name_of,epoch,train_cer/len(train_dataloader),val_loss_m,epochs )\n",
    "#     mlflow.log_metric(\"train_cer\",train_cer/len(train_dataloader))\n",
    "   # evaluate\n",
    "    model.eval()\n",
    "    valid_cer = 0.0\n",
    "    counts = 0\n",
    "    with torch.no_grad():\n",
    " \n",
    "        for batch in tqdm(eval_dataloader):\n",
    "            for k,v in batch.items():\n",
    "                batch[k] = v.cuda()  \n",
    "            # run batch generation\n",
    "#                 outputs = model.generate(batch[\"pixel_values\"].to(device))\n",
    "            outputs = model(**batch)\n",
    "            # compute metrics\n",
    "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "            cer = compute_cer(pred_ids=predictions, label_ids=batch[\"labels\"])\n",
    "            valid_cer += cer \n",
    "            counts += 1\n",
    "\n",
    "#                 info_emit(name_of,epoch,train_cer/len(train_dataloader),valid_cer/ counts,epochs )\n",
    "\n",
    "\n",
    "        print(\"Validation CER:\", valid_cer / len(eval_dataloader))\n",
    "#         info_emit(name_of,epoch,train_cer/len(train_dataloader),valid_cer / len(eval_dataloader),epochs )\n",
    "        val_loss_m = valid_cer / len(eval_dataloader)\n",
    "#         mlflow.log_metric(\"val_cer\",val_loss_m)\n",
    "\n",
    "    if(val_loss_min>val_loss_m):\n",
    "        val_loss_min = val_loss_m\n",
    "        print('Best',val_loss_min)\n",
    "        model.save_pretrained(save+\"Best\")\n",
    "#         mlflow.log_artifact(save+\"Best\")\n",
    "    model.save_pretrained(save)\n",
    "    result = pd.json_normalize(array_data_epochs)\n",
    "    result.to_csv('history_epochs_urdu_full.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
